# If you come from bash you might have to change your $PATH.
# export PATH=$HOME/bin:/usr/local/bin:$PATH
export TERM="xterm-256color"
export CURRENTPROJECT="$HOME/workspace/tal/tal/services/mrd_integration/"
export OS='/Users/craig.ferguson'
export STERN='stern --context staging'
export KUBE_UAT_NAMESPACE="wmstesting"
export KUBE_CRAIG_NAMESPACE="craig"
export OFFICE="kubectl --context staging"
export CK="$OFFICE --namespace $KUBE_CRAIG_NAMESPACE"
export UAT="$OFFICE --namespace wmsuat"
export WMSTESTING="$OFFICE --namespace $KUBE_UAT_NAMESPACE"
export MASTER="$OFFICE --namespace master"

alias wmsuat="$UAT"
alias checkout="kubectl --context staging --namespace checkout"
export namespace_command="$UAT"
export currentnamespace=wmsuat

export PIP_REQUIRE_VIRTUALENV=true
export TA=$HOME/workspace/dev-environments/kubernetes-environments/environment/roles/
export TP=$HOME/workspace/dev-environments/kubernetes-environments/environment/patches/development/
export CP=$HOME/workspace/cdev/kube/deployments
export PATH=$PATH:/opt/hub-linux-amd64-2.3.0-pre9/bin/
export PATH=$PATH:/opt/bin/
export PATCH=/home/craig/workspace/cdev/kube/patch.sh
#export GREP_OPTIONS='--color=auto'

alias branchinfo="cat $HOME/workspace/cdev/branches_reference"
alias branchinfoedit="vim $HOME/workspace/cdev/branches_reference"
alias removepyc='find . -name \*.pyc -delete'

alias v=vim .
#alias keys="vim $HOME/.vimkeys.vimrc"
alias keys="vim $HOME/keys.vimrc"
alias shortcuts="vim $HOME/.khdrc"
alias plug="vim $HOME/plug.vimrc"
alias dc=docker-compose
alias n="nautilus"
alias sos='cd ~/workspace/s4f-shipping-options-service'
alias lfi='cd ~/workspace/s4f-wms-logfire-integration'
alias mbs="cd $HOME/git_repos/mybondsite/backend;"
#
#alias officek='kubectl --context staging'
alias helpibt='open -a "Google Chrome" https://jira.takealot.com/wiki/display/TET/Auto+IBT+Process'
alias prodk='kubectl --context production'
pkd(){
  kubectl --context production delete pod $1
}
alias ck="$CK"
alias wmstesting="$WMSTESTING"
alias ka="kubectl attach -i -t"
alias office="$OFFICE"
alias master="$MASTER"
alias ptw="ptw -- -x --lf"
alias tal="cd $HOME/workspace/tal"
alias dimms="cd $HOME/workspace/s4f-dimension-processor"
alias sick="cd $HOME/workspace/s4f-sick-integration-service"
alias dis="cd $HOME/git_repos/distell"
alias testdjango="find . -name '*.py' | entr python ./manage.py test "
alias tdt='cd $HOME/workspace/tdt-integration-service'
alias wmsuata="$UAT attach -it "

ke() {
  kubectl exec -it $1 bash
}
# DIMs
dockerbuildpush() {
  docker build -t $1 .
  docker push $1
}

kewms() {
  SAVEIFS=$IFS
  IFS=$'\n'
  wms=$(kubectl get pod -o name | grep -v s3f | grep wms-service | sed 's/pods\///')
  echo $wms

# Change IFS to new line.
# Restore IFS
  IFS=$SAVEIFS

}
kk() {
  SAVEIFS=$IFS
  IFS=$'\n'
  #cublogfire=$(kubectl get pod -o name | grep s4f-dimension-processor-cub-logfire-consumer | sed 's/pods\///')
  #cubwms=$(kubectl get pod -o name | grep s4f-dimension-processor-cub-wms | sed 's/pods\///')
  #
  #dims=$(kubectl get pod -o name | grep s4f-dimension-processor | sed 's/pods\///')
  #echo $dims | xargs -n1 -P 3 kubectl  delete pod

  #wms=$(kubectl get pod -o name | grep wms-service | sed 's/pods\///')
  #echo $wms | xargs -n1 -P 3 kubectl  delete pod

  #log=$(kubectl get pod -o name | grep logfire-integration | sed 's/pods\///')
  #echo $log
  #echo $log | xargs -n1 -P 3 kubectl  delete pod

  #ship=$(kubectl get pod -o name | grep shipping-option | sed 's/pods\///')
  #kubectl delete pod $ship --grace-period=0
  #
  #kubectl delete pod $log --grace-period=0

  #tsm=$(kubectl get pod -o name | grep li-tsm | sed 's/pods\///')
  #kubectl delete pod $tsm --grace-period=0

  tdt=$(kubectl get pod -o name | grep tdt | sed 's/pods\///')
  echo $tdt | xargs -n1 -P 3 kubectl  delete pod

  #dash=$(kubectl get pod -o name | grep dashboard | sed 's/pods\///')
  #echo $dash | xargs -n1 -P 3 kubectl  delete pod

  #wms=$(kubectl get pod -o name | grep -v s3f | grep wms-service | sed 's/pods\///')
  #echo $wms | xargs -n1 -p 3 kubectl  delete pod

  #sleep 2
  #wms=$(kubectl get pod -o name | grep -v s3f | grep wms-service | sed 's/pods\///')
# echo into middle of command with xargs, install stuff
  #echo $wms | xargs -I % kubectl exec % -- pip install -r requirements.txt

# Change IFS to new line.
# Restore IFS
  IFS=$SAVEIFS

  #swms=$(kubectl get pod -o name | grep cpt-standard | sed 's/pods\///')
  #kubectl delete pod $dims
  #kubectl delete pod $dimsick
  #kubectl delete pod $cublogfire
  #kubectl delete pod $cubwms
}
# ______________________________________________________________________________
pushswms() {
  md
  #tag=kak
  tag=WMS-2365
  cd $HOME/workspace/service_wms && docker build -t image-registry.ci.env:80/takealot/service_wms:$tag . && docker push image-registry.ci.env:80/takealot/service_wms:$tag
  mycons=$(kubectl --context staging --namespace $currentnamespace get pod -o name | grep s3f-wms-mysql-consumer-cpt | sed 's/pods\///')
  myconstsin=$(kubectl --context staging --namespace $currentnamespace get pod -o name | grep s3f-wms-mysql-tsin-consumer-cpt | sed 's/pods\///')

  SAVEIFS=$IFS
  IFS=$'\n'
  wms=$(kubectl --context staging --namespace $currentnamespace get pod -o name | grep s3f-wms-service | sed 's/pods\///')

  kubectl --context staging --namespace $currentnamespace delete pod  $mycons

  echo $myconstsin | xargs -n1 -P 3 kubectl --context staging --namespace $currentnamespace delete pod
  echo $wms | xargs -n1 -P 3 kubectl --context staging --namespace $currentnamespace delete pod
  IFS=$SAVEIFS
}
watchuatrabbitqueues () {
  rabbit=$(kubectl --context staging --namespace $currentnamespace get pod -o name | grep rabbitmq-wms | sed 's/pods\///')
  kubectl --context staging --namespace $currentnamespace exec -it $rabbit -- rabbitmqctl list_queues -p wms
}
pushdash() {
  md
  #tag='WMS-3598'
  tag='dashboard-reship' # update orderitem on dashboard parcel management
  #wms388=('wms-service' 'dashboard' 'submit-po-to-adaptris' 'adaptris-service')
  wms3598=('wms-service' 'dashboard')

  cd $HOME/workspace/tal && docker build -t image-registry.ci.env:80/takealot/tal-with-requirements:$tag . && docker push image-registry.ci.env:80/takealot/tal-with-requirements:$tag
# Save current IFS
  SAVEIFS=$IFS
# Change IFS to new line.
  IFS=$'\n'
  wms=$(kubectl --context staging --namespace $currentnamespace get pod -o name | grep -v lb | grep wms-service | sed 's/pods\///')
  dash=$(kubectl --context staging --namespace $currentnamespace get pod -o name | grep -v lb | grep dashboard | sed 's/pods\///')
  #submitpo=$(kubectl --context staging --namespace $currentnamespace get pod -o name | grep -v lb | grep submit-po-to-adaptris | sed 's/pods\///')
  #adaptris=$(kubectl --context staging --namespace $currentnamespace get pod -o name | grep -v lb | grep adaptris-service | sed 's/pods\///')
  echo $wms | xargs -n1 -P 3 kubectl --context staging --namespace $currentnamespace delete pod
  echo $dash | xargs -n1 -P 3 kubectl --context staging --namespace $currentnamespace delete pod
  #echo $submitpo | xargs -n1 -P 3 kubectl --context staging --namespace $currentnamespace delete pod
  #echo $adaptris | xargs -n1 -P 3 kubectl --context staging --namespace $currentnamespace delete pod
# Restore IFS
  IFS=$SAVEIFS
  #printf "%s\n" "${wms388[@]}" | xargs -I % sh -c 'echo %; $UAT describe deployments % | grep image'
  printf "%s\n" "${wms3598[@]}" | xargs -I % sh -c 'echo %; $UAT describe deployments % | grep image'
}
pushsick() {
  md
  tag='WMS-3366'
  cd $HOME/workspace/s4f-sick-integration-service && docker build -t image-registry.ci.env:80/takealot/s4f-sick-integration-service:$tag . && docker push image-registry.ci.env:80/takealot/s4f-sick-integration-service:$tag
# Save current IFS
  SAVEIFS=$IFS
# Change IFS to new line.
  IFS=$'\n'
  sick=$(kubectl --context staging --namespace $currentnamespace get pod -o name | grep sick-client | sed 's/pods\///')
  echo $sick | xargs -n1 -P 3 kubectl --context staging --namespace $currentnamespace delete pod
# Restore IFS
  IFS=$SAVEIFS
}
# _________________________________________________________________________________
pushtdt() {
  md
  tag='WMS-3329'
  cd $HOME/workspace/tdt-integration-service/tdt-integration-service && docker build -t image-registry.ci.env:80/takealot/tdt-integration-service:$tag . && docker push image-registry.ci.env:80/takealot/tdt-integration-service:$tag
# Save current IFS
  SAVEIFS=$IFS
# Change IFS to new line.
  IFS=$'\n'
  tdt=$(kubectl --context staging --namespace $currentnamespace get pod -o name | grep -v s3f | grep tdt-integration-service | sed 's/pods\///')
  echo $tdt | xargs -n1 -P 3 kubectl --context staging --namespace $currentnamespace delete pod
# Restore IFS
  IFS=$SAVEIFS
}
pushsos() {
  md
  tag='WMS-3324'
  cd $HOME/workspace/s4f-shipping-options-service && docker build -t image-registry.ci.env:80/takealot/s4f-shipping-options-service:$tag . && docker push image-registry.ci.env:80/takealot/s4f-shipping-options-service:$tag
# Save current IFS
  SAVEIFS=$IFS
# Change IFS to new line.
  IFS=$'\n'
  sos=$(kubectl --context staging --namespace $currentnamespace get pod -o name | grep -v s3f | grep shipping-options-service | sed 's/pods\///')
  checkout_sos=$(kubectl --context staging --namespace checkout get pod -o name | grep -v s3f | grep shipping-options-service | sed 's/pods\///')
  testing_sos=$(kubectl --context staging --namespace wmstesting get pod -o name | grep -v s3f | grep shipping-options-service | sed 's/pods\///')
  echo $sos | xargs -n1 -P 3 kubectl --context staging --namespace $currentnamespace delete pod
  echo $checkout_sos| xargs -n1 -P 3 kubectl --context staging --namespace checkout delete pod
  echo $testing_sos| xargs -n1 -P 3 kubectl --context staging --namespace wmstesting delete pod
# Restore IFS
  IFS=$SAVEIFS
}
setimage_wms() {
  kubectl set image deployment/my-deployment mycontainer=myimage:latest
  kubectl --context staging --namespace $currentnamespace set image deployment/wms-service
}
pushwms() {
  md
  tag='WMS-3329'
  #tag='WMS-3784'
  tag=$dimstag
  cd $HOME/workspace/tal && docker build -t image-registry.ci.env:80/takealot/tal-with-requirements:$tag . && docker push image-registry.ci.env:80/takealot/tal-with-requirements:$tag
# Save current IFS
  SAVEIFS=$IFS
# Change IFS to new line.
  IFS=$'\n'
  wms=$(kubectl --context staging --namespace $currentnamespace get pod -o name | grep -v s3f | grep wms-service | sed 's/pods\///')
  echo $wms | xargs -n1 -P 3 kubectl --context staging --namespace $currentnamespace delete pod
# Restore IFS
  IFS=$SAVEIFS
}
stagealotcat() {
  ttab  -t "stagealot" "ssh -t -A toor@stagealot.com  cat /etc/bind/db.stagealot.com | grep  '$1'"
}
uatscalesftp() {
  md
  here=$(pwd)
# Save current IFS
  SAVEIFS=$IFS
# Change IFS to new line.
  IFS=$'\n'
  sftpwms=$(kubectl --context staging --namespace $currentnamespace get deployment -o name | grep s3f-wms-sftp | sed 's/deployments\///')

  echo $sftpwms
  echo $sftpwms | xargs -I % sh -c ' kubectl --context staging --namespace $currentnamespace scale deployment % --replicas 0'


  lfi=$(kubectl --context staging --namespace $currentnamespace get deployment -o name | grep logfire-integration- | sed 's/deployments\///')
  echo $lfi | xargs -I % sh -c ' kubectl --context staging --namespace $currentnamespace scale deployment % --replicas 1'

# Restore IFS
  IFS=$SAVEIFS
}
pushlfi() {
  md
  tag='WMS-2859-craig'
  cd $HOME/workspace/s4f-wms-logfire-integration && docker build -t image-registry.ci.env:80/takealot/s4f-wms-logfire-integration:$tag . && docker push image-registry.ci.env:80/takealot/s4f-wms-logfire-integration:$tag
# Save current IFS
  SAVEIFS=$IFS
# Change IFS to new line.
  IFS=$'\n'
  lfi=$(kubectl --context staging --namespace $currentnamespace get pod -o name | grep logfire-integration- | sed 's/pods\///')
  echo $lfi | xargs -n1 -P 3 kubectl --context staging --namespace $currentnamespace delete pod
# Restore IFS
  IFS=$SAVEIFS
}
pushdims() {
  md
  here=$(pwd)
  #tag='WMS-3638'
  tag=$dimstag
  cd $HOME/workspace/s4f-dimension-processor && docker build -t image-registry.ci.env:80/takealot/s4f-dimension-processor:$tag . && docker push image-registry.ci.env:80/takealot/s4f-dimension-processor:$tag
  cd $here
  wms=$(kubectl --context staging --namespace $currentnamespace get pod -o name | grep s4f-dimension-processor-cub-wms | sed 's/pods\///')
  cub=$(kubectl --context staging --namespace $currentnamespace get pod -o name | grep s4f-dimension-processor-cub-logfire | sed 's/pods\///')
  sick=$(kubectl --context staging --namespace $currentnamespace get pod -o name | grep s4f-dimension-processor-sick-consumer | sed 's/pods\///')
  tsm=$(kubectl --context staging --namespace $currentnamespace get pod -o name | grep s4f-dimension-processor-tsm-consumer | sed 's/pods\///')
  kubectl --context staging --namespace $currentnamespace delete pod  $tsm
  kubectl --context staging --namespace $currentnamespace delete pod  $sick
  kubectl --context staging --namespace $currentnamespace delete pod  $wms
  kubectl --context staging --namespace $currentnamespace delete pod  $cub
}
view_uat_kafka() {
  ssh toor@kafka02.stagealot.com /opt/kafka/bin/kafka-topics.sh --list --zookeeper 10.4.1.80:2181
}
kafka_view_uat_topic() {
  ssh toor@kafka02.stagealot.com /opt/kafka/bin/kafka-console-consumer.sh --topic $1 --zookeeper 10.4.1.80:2181
}
view_uat_kafka_pack() {
  ssh toor@kafka02.stagealot.com /opt/kafka/bin/kafka-console-consumer.sh --topic warehouse_pack --zookeeper 10.4.1.80:2181
}
kafka_prod_view() {
    ssh -t -A craigferguson@jump-box.takealot.com "ssh toor@kafka01 /opt/kafka/bin/kafka-topics.sh --list --zookeeper 10.2.17.1:2181"
  #echo "ssh kafka01"
  #echo '/opt/kafka/bin/kafka-console-consumer.sh --topic instructions_service --zookeeper 10.2.17.1:2181 --from-beginning'
  #echo '/opt/kafka/bin/kafka-topics.sh --list --zookeeper 10.2.17.1:2181'
}
view_kafka_PROD_topic() {
    ssh -t -A craigferguson@jump-box.takealot.com "ssh toor@kafka01 /opt/kafka/bin/kafka-console-consumer.sh --topic $1 --zookeeper 10.4.1.80:2181"
}
add_sftp_file_uat() {
  here=$(pwd)
  cd $HOME/workspace/cdev/helpers/sftp
  #python uat_sftp_client.py
  python sftp_adder.py
  cd $here
}
add_sftp_files() {
  #log=$(kubectl get pod -o name | grep -v Term | grep logfire-integration-cub | sed 's/pods\///')
  #echo $log
  #kubectl delete pod $log
  #sleep 2
  log=$(kubectl get pod -o name | grep logfire-integration-cub | sed 's/pods\///')
  echo $log
  kubectl exec -it $log python sftp_adder.py
}
add_sftp_iht() {
  here=$(pwd)
  cd $HOME/workspace/cdev/helpers/sftp
  python uat_sftp_iht.py
  cd $here
}

hiuat() {
  #tag='WMS-3009'
  #local tag=`git rev-parse --abbrev-ref HEAD`
  #local tag='WMS-388'
  #tag='master'
  tag=$dimstag
  echo 'installing tag '$tag
  helm upgrade --install $1 --kube-context staging  $2 --namespace $currentnamespace --set image.pullPolicy=Always,image.tag=$tag
}
hduat() {
  helm del --purge --kube-context staging $1
}
huatls() {
  helm --kube-context staging --namespace $currentnamespace ls
}
hmasterls() {
  helm --kube-context staging --namespace master ls
}

dimstag=WMS-3787

alias hwms="helm upgrade --install wms ~/workspace/tal/charts/wms-service/ --set image.pullPolicy=IfNotPresent,dev.patch=true,dev.mountPath=/usr/local/tal/tal,dev.hostPath=$HOME/workspace/tal,image.tag=master,resources.requests.cpu=300m,resources.limits.cpu=330,replicas=1 "
alias hshipwms="helm upgrade --install wms-shipping-service ~/workspace/tal/charts/wms-shipping-service/ --set image.pullPolicy=IfNotPresent,dev.patch=true,dev.mountPath=/usr/local/tal/tal,dev.hostPath=$HOME/workspace/tal,image.tag=master,resources.requests.cpu=300m,resources.limits.cpu=330,replicas=1 "
alias hdash="helm upgrade --install dash charts/dashboard --set dashboard.dev.patch=true,dashboardLb.dev.patch=true,dashboard.dev.hostPath=$HOME/workspace/tal,dashboardLb.dev.hostPath=$HOME/workspace/tal/tal/services/dashboard/static,dashboard.image.tag=master"
sostag='WMS-3324'
alias hsos="helm upgrade --install sos $OS/workspace/s4f-shipping-options-service/charts/s4f-shipping-options-service --set image.pullPolicy=IfNotPresent,dev.patch=true,dev.hostPath=$OS/workspace/s4f-shipping-options-service/shipping_options_service,dev.mountPath=/usr/local/tal/s4f-shipping-options-service/shipping_options_service,image.tag=$sostag,resources.requests.cpu=300m,resources.limits.cpu=330"
alias hdims="helm upgrade --install dimms $OS/workspace/s4f-dimension-processor/charts/s4f-dimension-processor --set image.pullPolicy=IfNotPresent,dev.patch=true,dev.hostPath=$OS/workspace/s4f-dimension-processor,dev.mountPath=/usr/local/tal/s4f-dimension-processor,image.tag=$dimstag,resources.requests.cpu=300m,resources.limits.cpu=330"
alias hlfi="helm upgrade --install lfi $OS/workspace/s4f-wms-logfire-integration/charts/s4f-wms-logfire-integration --set image.pullPolicy=IfNotPresent,dev.patch=true,dev.hostPath=$OS/workspace/s4f-wms-logfire-integration,dev.mountPath=/usr/local/tal/s4f-wms-logfire-integration,image.tag=WMS-2859,resources.requests.cpu=300m,resources.limits.cpu=330"
alias hswms="helm upgrade --install service-wmsm ~/workspace/service_wms/charts/s3f-wms-service/ --set image.pullPolicy=IfNotPresent,dev.patch=true,dev.hostPath=$OS/workspace/service_wms,resources.requests.cpu=400m,resources.limits.cpu=430 "
alias hswms_sftp_consumers="helm upgrade --install swms-sftp-cons ~/workspace/service_wms/charts/s3f-wms-sftp-consumers/ --set image.pullPolicy=IfNotPresent,dev.patch=true,image.tag=WMS-2365,dev.hostPath=$OS/workspace/service_wms,resources.requests.cpu=400m,resources.limits.cpu=430 "
alias hsick="helm upgrade --install sick-service $HOME/workspace/s4f-sick-integration-service/charts/s4f-sick-integration-service --set image.pullPolicy=IfNotPresent,dev.patch=true,dev.mountPath=/usr/local/tal/s4f-sick-integration-service,dev.hostPath=$HOME/workspace/s4f-sick-integration-service,resources.requests.cpu=300m,resources.limits.cpu=330,image.tag=WMS-3366"
alias htimer="helm upgrade --install s4f-timer-service ~/workspace/s4f-timer-service/charts/s4f-timer-service --set image.pullPolicy=IfNotPresent,dev.patch=true,dev.mountPath=/usr/local/tal/s4f-timer-service,dev.hostPath=`pwd`/workspace/s4f-timer-service,resources.requests.cpu=300m,resources.limits.cpu=330 "
alias horders="helm upgrade --install order-service ~/workspace/tal/charts/order-service --set image.pullPolicy=Always,dev.patch=true,dev.mountPath=/usr/local/tal/tal,dev.hostPath=$HOME/workspace/tal,resources.requests.cpu=300m,resources.limits.cpu=330 "
alias hcomms="helm upgrade --install comms ~/workspace/s4f-comms-service/charts/s4f-comms-service --set image.pullPolicy=IfNotPresent,dev.patch=true,dev.mountPath=/usr/local/tal/s4f-comms-service/comms_service,dev.hostPath=$HOME/workspace/s4f-comms-service/comms_service,resources.requests.cpu=300m,resources.limits.cpu=330 "
alias hdel='helm del --purge'
htdt () {
  tag='WMS-3329'
  cd ~/workspace/tdt-integration-service/tdt-integration-service
  helm upgrade --install tdt --set dev.patch=true,dev.hostPath=$PWD/tdt_integration_service,image.tag=$tag charts/tdt-integration-service
}
generate_proto_tdt() {
  /Users/craig.ferguson/workspace/tdt-integration-service/scripts/generate_proto.sh
}
#watch network
alias watchnet="watch -n 1 'sudo netstat -tanop'"
alias watchsockets="watch -n 1 'ss -s'"

alias suat="stern --context staging -n $currentnamespace"
alias scheckout="stern --context staging -n checkout"
alias stesting="stern --context staging -n wmstesting"
alias smaster="stern --context staging -n master"
alias sprod="stern --context production"
alias resumekube='~/workspace/tal-kubernetes/bin/resume-minikube.sh'
fucksky() {
  sky=$(kubectl get pod --namespace kube-system -o name | grep skywriter  | sed 's/pods\///')
  kubectl delete pod --namespace kube-system $sky
}
fuckpycache() {
  sudo rm -rf .pytest_cache
}
hsftp() {
 cd /Users/craig.ferguson/workspace/cdev/kube/deployments
 kubectl create -f sftp
}
wmsuatupdatetags() {

  #tag=WMS-3333
  #wms-service
  #    Image:      image-registry.ci.env:80/takealot/tal-with-requirements:WMS-3709
  #    dashboard
  #        Image:      image-registry.ci.env:80/takealot/tal-with-requirements:WMS-3787]
  tag=dashboard-reship
  wms388=('wms-service' 'dashboard' 'submit-po-to-adaptris' 'adaptris-service')
  #echo "388 User logging"
  dash=('wms-service' 'dashboard')

  echo "dashbaord fix"
  #printf "%s\n" "${wms388[@]}" | xargs -I % sh -c 'echo %; $namespace_command set image deployments/%  %=image-registry.ci.env:80/takealot/tal-with-requirements:WMS-388'
  printf "%s\n" "${dash[@]}" | xargs -I % sh -c 'echo %; $namespace_command set image deployments/%  %=image-registry.ci.env:80/takealot/tal-with-requirements:dashboard-reship'
  echo ''

}

wmsuatimages() {

  wms3769=('s4f-dimension-processor' 'wms-service')
  wms3765=('wms-service' 'dashboard')
  dashboardreship=('wms-service' 'dashboard')
  wms3589=('wms-service' 'dashboard' 's4f-dimension-processor')
  wms3329=('wms-service' 'tdt-integration-service')
  wms2365=('s3f-wms-service' 's3f-wms-mysql-consumer-cpt' 's3f-wms-mysql-tsin-consumer-cpt' 'wms-service')
  clickncollect=('wms-service' 'tdt-integration-service' 'delivery-service')

  #wms3366=('s4f-dimension-processor' 's4f-sick-client-cpt-inline-01' 's4f-dimension-processor-cub-logfire-consumer' 's4f-wms-logfire-integration-cub-poller-cpt' 's4f-wms-logfire-integration-cub-poller-jhb' 's4f-wms-logfire-integration-sic-poller-cpt' 's4f-wms-logfire-integration-sic-poller-jhb' 's4f-wms-logfire-integration-tsm-poller-cpt' 's4f-wms-logfire-integration-tsm-poller-jhb')
  wms3366=('s4f-dimension-processor' 's4f-sick-client-cpt-inline-01' 's4f-wms-logfire-integration-sic-poller-cpt' 's4f-wms-logfire-integration-sic-poller-jhb')


  echo "3769 move cub message to consumer and out of dimension processor"
  echo "https://jira.takealot.com/jira/browse/WMS-3769"
  printf "%s\n" "${wms3769[@]}" | xargs -I % sh -c 'echo %; $namespace_command describe deployments % | grep image'
  echo ''


  echo "3765 Add repack button to dashboard for when messages fail into wmsapi"
  echo "https://jira.takealot.com/jira/browse/WMS-3765"
  echo "https://github.com/TAKEALOT/tal/pull/7707"
  printf "%s\n" "${wms3765[@]}" | xargs -I % sh -c 'echo %; $namespace_command describe deployments % | grep image'
  echo ''

  echo "3329 Order Injections DOP"
  echo "https://jira.takealot.com/jira/browse/WMS-3329"
  echo "https://github.com/TAKEALOT/tal/pull/7711 WMS-3329"
  echo "https://github.com/TAKEALOT/tdt-integration-service/pull/2"
  printf "%s\n" "${wms3329[@]}" | xargs -I % sh -c 'echo %; $namespace_command describe deployments % | grep image'
  echo ''

  #echo "2365 Voetstoets"
  #printf "%s\n" "${wms2365[@]}" | xargs -I % sh -c 'echo %; $namespace_command describe deployments % | grep image'
  #echo ''

  echo "3366 Sick Integration 3009 dims logfire int 2859"
  printf "%s\n" "${wms3366[@]}" | xargs -I % sh -c 'echo %; $namespace_command describe deployments % | grep image'
  echo ''

  echo  "Update OrderItems directly in field on dashboard, TESTED DEPLOY"
  echo "3589 need to do a check for the order items"
  echo "https://jira.takealot.com/jira/browse/WMS-3589"
  echo "https://github.com/TAKEALOT/tal/pull/7691/files"
  printf "%s\n" "${wms3589[@]}" | xargs -I % sh -c 'echo %; $namespace_command describe deployments % | grep image'
  echo ''

  echo "dashboard-reship fix poll queue filters"
  printf "%s\n" "${dashboardreship[@]}" | xargs -I % sh -c 'echo %; $namespace_command describe deployments % | grep image'
  echo ''
}
#mongo_prod_query() {
    #ssh -A craigferguson@jump-box.takealot.com
    #mongo mongo02:27017/talSet
    #use takealot;
    #rs.slaveOk();
    #show collections;
    #db.<collection>.find({_id: ObjectId("<Object ID>")})
    ##* Use 'show collections' to show available collections
    ##* To find the latest record
    #db.collection.find().limit(1).sort({$natural:-1}).pretty()
    ##db.addressbook.update({_id: ObjectId("5a6f8068404b4700129d8c1c")}, {$set: { "fields.addressee": "Luis Alberto Perera Perera Hernandez"}})
#}
restartsickserver() {

  SAVEIFS=$IFS
  IFS=$'\n'
  services=('socket-server')
  for i in $services; do
    wms=$(kubectl --context staging --namespace wmsuat get pods -o name | grep -v s3f | grep $i | sed 's/pods\///')
    echo $wms | xargs -I % sh -c '$UAT delete pod % '
  done
  IFS=$SAVEIFS
  sleep 7
  services=('socket-server')
  server=$(kubectl --context staging --namespace wmsuat get pods -o name | grep -v s3f | grep $i | sed 's/pods\///')
  echo $server
  echo $server | xargs -I % sh -c '$UAT attach -it pod % '
}
wmsuatrestart() {

  SAVEIFS=$IFS
  IFS=$'\n'

  services=('wms-service' 'dashboard' 's3f-wms-service', 'submit-po-to-adaptris', 'adaptris-service')

  for i in $services; do
    wms=$(kubectl --context staging --namespace wmsuat get pods -o name | grep -v s3f | grep $i | sed 's/pods\///')
    echo $wms | xargs -I % sh -c '$UAT delete pod % '
  done

  IFS=$SAVEIFS

}
#watching kubes
#alias watch1="$HOME/workspace/cdev/kube/watch_kube.py kubectl"
#alias watch1="watch -n 1 'kubectl get pods --all-namespaces'"
#alias watchuat="$HOME/workspace/cdev/kube/watch_uat.py"
#alias watch2="$HOME/workspace/cdev/kube/watch_kube.py '$CK'"

alias pods_wmstesting="watch -n 1 'kubectl --context staging --namespace wmstesting get pods'"
alias protoc26='/usr/local/opt/protobuf@2.6/bin/protoc'

generateprotota(){
  #protoc26 -I=$SRC_DIR_of_.proto_files --python_out=$DST_DIR_for.py_serializers $SRC_DIR/path_to_file.proto
  protoc26='/usr/local/opt/protobuf@2.6/bin/protoc'
  cd $HOME/workspace/s4f-protocol-buffers
  protoc26 -I . --python_out=../s4f-python-clients/s4f_clients/compiled_protobuffs ./*.proto
  protoc26 -I . --python_out=../s4f-comms-service/comms_service/compiled_protobuffs ./*.proto
  protoc26 -I . --python_out=../s4f-shipping-options-service/shipping_options_service/compiled_protobuffs ./*.proto
}
alias generate_comms_service_protobuffs=""


restart_kube() {
  minikube stop
  minikube start
  echo 'md'
}
watch_wmstesting() {
  #sftp=$(kubectl --context staging --namespace wmstesting get pod -o name | grep sftp-wms | sed 's/pods\///')

  # give sftp in wmstesting so can copy files
  #$HOME/workspace/cdev/kube/watch_pods.py $WMSTESTING $sftp

  # watch logs for testing namespace tsin specific
  $HOME/workspace/cdev/kube/sterntsinconsumers.py wmstesting
}
wmsuate() {
  kubectl --context staging --namespace $currentnamespace exec -it $1 bash
}
watchuat() {
  ttab -t "UAT"  "watch -n 1 'kubectl --context staging get pods --namespace $currentnamespace'"
  ttab -t "UAT"  "watch -n 1 'kubectl --context staging get services --namespace $currentnamespace'"
}
watch1() {
  ttab -t "MINIKUBE"  "watch -n 1 'kubectl get pods --all-namespaces'"
  ttab -t "MINIKUBE"  "watch -n 1 'kubectl get services --all-namespaces'"
}
watch_mini() {
  $HOME/workspace/cdev/kube/stern_local.py
  $HOME/workspace/cdev/kube/watch_pods.py kubectl
  exit
}
lf () {
  ls | grep $1
}

watch3() {
  #lsftp=$(kubectl get pod -o name | grep tsin-dimensions-sftp | sed 's/pods\///')
  sftp=$(kubectl --context staging --namespace $currentnamespace get pod -o name | grep sftp-wms | sed 's/pods\///')
  #poller=$(kubectl --context staging --namespace wmstesting get pod -o name | grep cub-poller | sed 's/pods\///')
  #if [[ -z $lsftp ]]
    #then
    #echo 'please make sure local tsin-dims sftp consumer is running'
  #fi
  #if [[ -z $sftp ]]
    #then
    #echo 'please make sure sftp is running in uat namespace : wmstesting'
  #fi
  #if [[ -z $poller ]]
    #then
    #echo 'please make sure cub poller is running in uat namespace'
  #fi
  $HOME/workspace/cdev/kube/watch_pods.py $UAT $sftp
# pass in namespace as first arg
  $HOME/workspace/cdev/kube/sterntsinconsumers.py wmsuat
}
start_code() {
  nohup hipchat4 &
  nohup chromium --new-window https://calendar.google.com/calendar/render
}
sftp_uat() {
  echo '(|EP4).C'
  sftp takealot_uat_if@uatsftp.logfireapps.com
}
sftp_box(){
 export sftp="Pt8e$d7W%7e"
 sftp takealotif@b1sftplogfireapps.com
}
#add_sftp_file(){
  #sftp=$(kubectl --context staging --namespace wmstesting get pod -o name | grep sftp-wms | sed 's/pods\///')
  #wmstesting exec -i -t $sftp -- bash -c "cp /tmp/CUB_TEST_001 /home/wms/data/TAL/CPT/output/$1"

  #sshpass -e sftp -oBatchMode=no -b - takealot_uat_if@uatsftp.logfireapps.com
#sshpass -e sftp -oBatchMode=no -b - sftp-user@remote-host << !
   #cd incoming
   #put your-log-file.log
   #bye
#!
#}

#run interactive
alias r1wms="kubectl run wms-service -i --tty --image 10.4.1.39:5000/takealot/tal-with-requirements:master --env='ROLE=KUBERNETES' -- bash -c '/usr/local/tal/tal/bin/gunicorn-docker-entry.sh \"tal.services.wms.server:application\"'"
#temp create c delete d for k8s:
#alias c1adap="kubectl create -f $TA/adaptris-service"
#alias d1adap="kubectl delete -f $TA/adaptris-service"
#alias c1wms="cat $TA/wms-service/wms-deployment.yaml | sed 's|imagePullPolicy: Always|imagePullPolicy: IfNotPresent|' | kubectl create -f -; kubectl create -f $TA/wms-service/wms-service.yaml"
#alias d1wms="kubectl delete -f $TA/wms-service"
#alias c1dims="kubectl create -f $TA/s4f-dimension-processor-service/warehouse-tsin-dimensions-sftp-consumer-deployment.yaml"
#alias d1dims="kubectl delete -f $TA/s4f-dimension-processor-service/warehouse-tsin-dimensions-sftp-consumer-deployment.yaml"
#alias c1kafka="kubectl create -f $TA/kafka/"
#alias d1kafka="kubectl delete -f $TA/kafka/"
#alias c1ingress="kubectl create -f $TA/ingress/"
#alias d1ingress="kubectl delete -f $TA/ingress/"

alias csicks="kubectl create -f $HOME/workspace/cdev/kube/deployments/sick_server"
alias dsicks="kubectl delete -f $HOME/workspace/cdev/kube/deployments/sick_server --grace-period=5"
alias csickc="kubectl create -f $HOME/workspace/cdev/kube/deployments/sick-client-deployment.yml"
alias dsickc="kubectl delete -f $HOME/workspace/cdev/kube/deployments/sick-client-deployment.yml --grace-period=5"
#alias csickc="kubectl create -f $HOME/workspace/cdev/kube/deployments/sick-client-pdb-deployment.yml"
#alias dsickc="kubectl delete -f $HOME/workspace/cdev/kube/deployments/sick-client-pdb-deployment.yml"
alias csftp="kubectl create -f $TA/sftp/"
alias dsftp="kubectl delete -f $TA/sftp/"
alias d2wms="$CK delete -f $TA/wms-service"
alias c2dims="$CK create -f $TA/s4f-dimension-processor-service/"
alias d2dims="$CK delete -f $TA/s4f-dimension-processor-service/"
alias c2sftp="$CK create -f $TA/sftp/"
alias d2sftp="$CK delete -f $TA/sftp/"

alias c3wms="$WMSTESTING create -f $TA/wms-service"
alias d3wms="$WMSTESTING delete -f $TA/wms-service"
alias c3dims="$WMSTESTING create -f $TA/s4f-dimension-processor-service/"
alias d3dims="$WMSTESTING delete -f $TA/s4f-dimension-processor-service/"
alias c3sftp="$WMSTESTING create -f $TA/sftp/"
alias d3sftp="$WMSTESTING delete -f $TA/sftp/"

#execute e temp
alias e1wms="kubectl run c-wms-shell --rm -i --tty --image 10.4.1.39:5000/takealot/tal-with-requirements -- bash"
#alias e1dims="kubectl run c-dims-shell --rm -i --tty --image 10.4.1.39:5000/takealot/s4f-dimension-processor:master -- bash"

#DEBUGGING DIMS
alias dec1dimssftp="kubectl create -f $CP/sftp-dimensions-consumer.yaml"
alias ded1dimssftp="kubectl delete -f $CP/sftp-dimensions-consumer.yaml"
alias dec1dimswmsapi="kubectl create -f $CP/wmsapi-dimensions-consumer.yaml"
alias ded1dimswmsapi="kubectl delete -f $CP/wmsapi-dimensions-consumer.yaml"
dee1dimssftp() {
  kubectl exec -i -t $1 -- bash -c "kafka_consumer --consumer_type tsin_dimensions_sftp"
}
dee1dimswmsapi() {
  kubectl exec -i -t $1 -- bash -c "kafka_consumer --consumer_type tsin_dimensions_wmsapi"
}
alias e1dims2166="kubectl run c-dims-shell --rm -i --tty --image 10.4.1.39:5000/takealot/warehouse_pack:master -- bash"

#
#patch
alias p1adap="$PATCH $TP/adaptris-deployment.yaml"
p1dims() {
  $PATCH $TP/s4f-dimension-processor/warehouse-tsin-dimensions-sftp-consumer-deployment.yaml
  $PATCH $TP/s4f-dimension-processor/warehouse-tsin-dimensions-wmsapi-consumerdeployment.yaml
}
#
#view v
alias vwms="cd $HOME/workspace/tal/tal/services/wms/"
alias vdims="cd $HOME/workspace/s4f-dimension-processor/;vim ."
alias vadap="cd $HOME/workspace/tal/tal/services/adaptris/;vim ."
alias vmrd="cd $HOME/workspace/tal/tal/services/mrd_integration/;vim ."
alias vkaf="cd $HOME/workspace/tal-kafka/;vim ."
alias run="python manage.py runserver"
#alias size="/home/craig/.screenlayout/laptop.sh"
alias rec="/home/craig/git_repos/receipts/receipts_server"
alias kaf="cd $HOME/git_repos/kafka/code;"

alias k="kubectl"
alias khsetup="source <(helm completion zsh)"
alias ksetup="source <(kubectl completion zsh)"
alias kc="kubectl create"
alias kgp="kubectl get pods -owide --all-namespaces --show-all"
alias pgp="kubectl --context production get pods -owide --all-namespaces --show-all"
alias kdd="kubectl delete deployment"
alias minikubedockerexit='eval $(minikube docker-env -u)'
alias reload='exec $SHELL -l'
alias pj='cd ~/git_repos/psychicjenha/frontend'
alias tk='cd ~/workspace/tal-kubernetes'
alias set="source <(kubectl completion zsh)"
alias pa="pyenv activate testing; ipython"
alias config="vim ~/.zpreztorc;"
alias ipy=ipython
alias edit='vim ~/.zpreztorc'
eval $(thefuck --alias f)
fpath=(~/.zsh/completion $fpath)
autoload -Uz compinit && compinit -i

alias gitalias='vim $HOME/.zprezto/modules/git/alias.zsh'
alias gst="git status"
alias gp="git pull"
alias kafcreate='hello'
#patches to k8s
alias p1wms='$HOME/workspace/cdev/kube/patch.sh $TP/wms-deployment.yaml'

#temps
alias ipyvim='pyenv activate neovim3; ipython kernel; watch'
alias es='cd ~/workspace/tal_big_data/reports/2017-06_grad_big_data/'
alias sickd='cd ~/workspace/dev-environments/kubernetes-environments/environment/roles/s4f-sick-integration-service/'
alias adapt='cd ~/workspace/tal/tal/services/adaptris/test/;'
alias sis='cd ~/workspace/s4f-sick-integration-service/'
alias gogo='cd $HOME/git_repos/kafka/code && ./tal-commands.py'
alias prod="$CURRENTPROJECT;vim ."
#end temps
#
#
restartDjango() {
  find . -path "*/migrations/*.py" -not -name "__init__.py" -delete
  find . -path "*/migrations/*.pyc"  -delete
  rm db.sqlite3
  python manage.py makemigrations
  python manage.py migrate
  python manage.py runserver
}
eval "$(pyenv init -)"
eval "$(pyenv virtualenv-init -)"
setopt correct
unsetopt correctall

wmsuate() {
    kubectl --context staging --namespace wmsuat exec -i -t $1 bash
}
pep() {
    kubectl --context production exec -i -t $1 bash
}

zstyle ':prezto:load' pmodule \
         'environment' \
         'terminal' \
         'tmux' \
         'editor' \
         'history' \
         'directory' \
         'spectrum' \
         'utility' \
         'completion' \
         'git' \
         'syntax-highlighting' \
         'history-substring-search' \
         'prompt'
zstyle ':prezto:module:prompt' theme 'smiley'
savehelp() {
  echo "$@[2,-1]" >> $HOME/git_repos/craig_help/$1
}
pushtalbranchImage() {
  # get the git branch name
  cd $HOME/workspace/tal/
  export BRANCH=`git rev-parse --abbrev-ref HEAD`
  echo 'working on branch '$BRANCH
  # build the container
  export IMAGE_PATH="10.4.1.39:5000/takealot/tal-with-requirements:${BRANCH}"
  docker build -t ${IMAGE_PATH} -f Dockerfile .
  docker push ${IMAGE_PATH}
}
krun() {
  k run my-shell --rm -i --tty --image 10.4.1.39:5000/takealot/warehouse_pack:master -- bash -c " pip install pudb;export ROLE=KUBERNETES;export ENVIRONMENT=STAGING; kafka_consumer --consumer_type tsin_dimensions_sftp
"
}
prodke() {
  kubectl --context production exec -it $1 bash
}
#krun2() {
  #kubectl --context production exec -i --tty $1 -- bash -c "kafka_consumer --consumer_type tsin_dimensions_sftp"
#}
krun2() {
  k exec -i --tty $1 -- bash -c "kafka_consumer --consumer_type tsin_dimensions_sftp"
}
gac() {
  git add .
  git commit -m "{$@}"
}
ghist() {
	git log --oneline --graph --decorate --all
}
gc() {
  if [[ $1 -eq master ]]
    then
      git checkout master
    else
      git checkout WMS-"$@"
  fi

}
envv() {
  if [[ $# -eq 0 ]]
    then
      env
    else
      env | grep -i $1
  fi
}
kin () {
  kubectl run -i --tty temp --image=$1 --restart=Never -- sh
}
restartn() {
  sudo service networking restart;
  sudo service network-manager restart;
}
pullta() {
  a=$(git status | grep -c "modified")
  if [[ $a > 0 ]]
  then
    echo ''
    echo 'you have changes';
    echo ''
  else
    git pull
  fi
}

kill_local() {
  NAME=$(kubectl get pod -o name | grep wmsapi-consumer | sed 's/pods\///')
  wmsapi=$(kubectl get pod -o name | grep wmsapi-consumer | sed 's/pods\///')
  kubectl delete pod  $NAME
  kubectl delete pod  $wmsapi
}
TESTD() {
  NAME=$(kubectl get pod -o name | grep dimensions | sed 's/pods\///')
  kubectl exec  $NAME -- bash -c "pip install pytest pudb unittest2 mock"
  kubectl exec -i -t $NAME -- bash -c "cd dimension_processor/tests;pytest -s -x --lf test_dimension_processor.py"
}
testtdt() {
  cd $HOME/workspace/tdt-integration-service
  NAMES=$(kubectl get pod -o name | grep tdt-integration-service  | sed 's/pods\///')
  read -r NAME <<< "$NAMES"
   echo $NAME
  #NAME=$($namespace_command get pod -o name | grep wms-service | sed 's/pods\///')
  kubectl exec  $NAME -- bash -c "pip install pytest unittest2 mock"
  #kubectl exec  $NAME -- bash -c "pytest -s shipping_options_service/tests/test_service_endpoints.py"
  find . -name '*.py' | entr kubectl exec  $NAME -- bash -c "pytest -s tests/integration_tests/test_order_injection_consumer.py"
  }

testpipe() {
  cd /Users/craig.ferguson/workspace/data_pipeline/
  find . -name '*.py' | entr pytest -s tests/unit_tests/core/test_pipeline.py
}

testesc() {
  cd ~/workspace/s4f-dimension-processor
  NAMES=$(kubectl get pod -o name | grep dimension-processor  | sed 's/pods\///')
  read -r NAME <<< "$NAMES"
  echo $NAME
  kubectl exec  $NAME -- bash -c "pip install pytest unittest2 mock"
  find . -name '*.py' | entr kubectl exec  $NAME -- bash -c "pytest -s dimension_processor/tests/test_elastic_search_consumer.py"
}
testwms() {
  SAVEIFS=$IFS
  cd $HOME/workspace/tal
  IFS=$'\n'
  NAMES=$(kubectl get pod -o name | grep -v s3f | grep -v Terminating | grep wms-service  | sed 's/pods\///')
  #
  read -r NAME <<< "$NAMES"
  #NAME=$($namespace_command get pod -o name | grep wms-service | sed 's/pods\///')
  kubectl exec  $NAME -- bash -c "pip install pytest unittest2 mock"
  #kubectl exec  $NAME -- bash -c "pytest -s shipping_options_service/tests/test_service_endpoints.py"
  #find . -name '*.py' | entr kubectl exec  $NAME --  bash -c "pytest -s tal/services/wms/test/test_shipping_queue_utilities.py"
# move order injections out of tal:
  find . -name '*.py' | entr kubectl exec  $NAME --  bash -c "pytest -s tal/services/wms/test/test_wms_client.py"
  IFS=$SAVEIFS
}
testsos() {
  cd ~/workspace/s4f-shipping-options-service
  NAMES=$(kubectl get pod -o name | grep shipping-options  | sed 's/pods\///')
  read -r NAME <<< "$NAMES"
   echo $NAME
  #NAME=$($namespace_command get pod -o name | grep wms-service | sed 's/pods\///')
  kubectl exec  $NAME -- bash -c "pip install pytest unittest2 mock"
  #kubectl exec  $NAME -- bash -c "pytest -s shipping_options_service/tests/test_service_endpoints.py"
  find . -name '*.py' | entr kubectl exec  $NAME -- bash -c "pytest -s shipping_options_service/tests/test_service_endpoints.py"
  #find . -name '*.py' | entr kubectl exec  $NAME -- bash -c "pytest -s shipping_options_service/tests/test_schemas.py"
}
TESTdims() {
  NAME=$(kubectl get pod -o name | grep processor-sick-consumer | sed 's/pods\///')
  kubectl exec  $NAME -- bash -c "pip install pytest pudb unittest2"
  kubectl exec  $NAME -- bash -c "pytest -s dimension_processor/tests/test_consumers_warehouse_pack_handler.py"
}
TESTdash() {
   echo $currentnamespace
   NAME=$(kubectl --context staging --namespace $currentnamespace get pods -o name | grep wms-service | sed 's/pods\///')
   echo $NAME
  #NAME=$($namespace_command get pod -o name | grep wms-service | sed 's/pods\///')
  kubectl --context staging --namespace $currentnamespace exec  $NAME -- bash -c "pip install pytest pudb unittest2"
  kubectl --context staging --namespace $currentnamespace exec  $NAME -- bash -c "pytest -s tal/services/wms/test/test_wms_AuditLogger.py"
}
testdash() {
  NAMES=$(kubectl get pod -o name | grep -v s3f | grep -v Terminating | grep wms-service  | sed 's/pods\///')
  read -r NAME <<< "$NAMES"
   echo $NAME
  #NAME=$($namespace_command get pod -o name | grep wms-service | sed 's/pods\///')
  kubectl exec  $NAME -- bash -c "pip install pytest pudb unittest2"
  kubectl exec  $NAME -- bash -c "pytest -s tal/services/wms/test/test_wms_AuditLogger.py"
}
TESTlfi() {
  cd $HOME/workspace/s4f-wms-logfire-integration;
  find . -name '*.py' | entr /Users/craig.ferguson/workspace/cdev/helpers/TESTWmsLogfire.sh
}
TESTwmsapi() {
  SAVEIFS=$IFS
  IFS=$'\n'
  NAMES=$(kubectl get pod -o name | grep -v s3f | grep -v Terminating | grep wms-service  | sed 's/pods\///')
  #
  read -r NAME <<< "$NAMES"
  #NAME=$($namespace_command get pod -o name | grep wms-service | sed 's/pods\///')
  kubectl exec  $NAME -- bash -c "pip install pytest unittest2 mock"
  #kubectl exec  $NAME -- bash -c "pytest -s shipping_options_service/tests/test_service_endpoints.py"
  find . -name '*.py' | entr kubectl exec  $NAME --  bash -c "pytest -s tal/services/wms/test/test_wms_client.py"
  IFS=$SAVEIFS
}
TESTMR() {
  #run deployment in minikube
  NAME=$(kubectl get pod -o name | grep mrd | sed 's/pods\///')
  kubectl exec  $NAME -- bash -c "pip install pytest pudb unittest2 mock"
  #run tests
  kubectl exec  $NAME -- bash -c "pytest services/tests/test_split_shipments.py"

  #expose pod
  #
  #curl endpoint with some data
}
TESTA() {
  $PATCH $TP/adaptris-deployment.yaml
  kubectl exec  $1 -- bash -c "pip install pytest pudb unittest2"
  kubectl exec -i -t $1 -- bash -c "cd tal/services/adaptris/test;pytest -s -x --lf test_adaptris_integration.py"
}
checkgitta() {
  for foldr in ~/workspace/*/;
    do
      cd foldr;
      echo "$foldr"
      git fetch;
      pullta
    done;
}

md() {
  eval $(minikube docker-env)
  minikube ssh "echo 'Domains=stagealot.com' | sudo tee -a /etc/systemd/resolved.conf"
  minikube ssh "sudo systemctl restart systemd-resolved.service"
}
findinfiles() {
  find . -iname $1 | ack --files-from=- $2
}
dcc() {
  dc ps | grep Exit
}
dcu() {
  dc up -d --force-recreate $1
}
odev() {
cd workspace/dev-environments/docker-environment/collections && source compose.env
cd ~/workspace/dev-environments/docker-environment/collections/shared/wms-staging/
}
dev() {
cd ~/workspace/cdev/$1
}

devup() {
cd ~/workspace/dev-environments/docker-environment/collections && source compose.env
cd ~/workspace/cdev/$1
dc up --force-recreate;
}
h() {
  cd ~/git_repos/craig_help
  ls;
}
devad() {
cd ~/workspace/dev-environments/docker-environment/collections && source compose.env
cd ~/workspace/cdev/adaptris
dc exec adaptris pip install pytest pytest-watch;
dc exec adaptris bash -c 'cd tal/services/adaptris/test; ptw -- -x --lf;';
}
update-delete-repo() {
  cd $1 && git remote -vv && cd .. && sudo rm -rf $1
}
code-on() {
  git checkout -b $1 origin/master
}
jumpbox() {
  ssh-add
  ssh -A craigferguson@jump-box.takealot.com
}
grep_restapi01() {
  ttab  -t "Rest API 01" "ssh -t -A craigferguson@jump-box.takealot.com \"ssh tal-rest-api01 'cat /var/log/supervisor/services.order.error.log*'\" | grep '$1'"
}
grep_restapi02() {
  ttab  -t "Rest API 02" "ssh -t -A craigferguson@jump-box.takealot.com \"ssh tal-rest-api02 'cat /var/log/supervisor/services.order.error.log*'\" | grep '$1'"
}
grep_restapi03() {
  ttab  -t "Rest API 03" "ssh -t -A craigferguson@jump-box.takealot.com \"ssh tal-rest-api03 'cat /var/log/supervisor/services.order.error.log*'\" | grep '$1'"
}
grep_restapi04() {
  ttab  -t "Rest API 04" "ssh -t -A craigferguson@jump-box.takealot.com \"ssh tal-rest-api04 'cat /var/log/supervisor/services.order.error.log*'\" | grep '$1'"
}
grep_orders() {
  ssh-add
  $(grep_restapi01 "$1")
  $(grep_restapi02 "$1")
  $(grep_restapi03 "$1")
  $(grep_restapi04 "$1")
}
grep_wmsapi02() {
  ttab  -t "WMSAPI02" "ssh -t -A craigferguson@jump-box.takealot.com \"ssh wmsapi02 'cat /var/log/supervisor/services.wms.error.log*'\" | grep '$1'"
}
grep_wmsapi03() {
  ttab  -t "WMSAPI03" "ssh -t -A craigferguson@jump-box.takealot.com \"ssh wmsapi03 'cat /var/log/supervisor/services.wms.error.log*'\" | grep -B 10 -A 10 '$1'"
}
grep_wmsapi05() {
  ttab  -t "WMSAPI05" "ssh -t -A craigferguson@jump-box.takealot.com \"ssh wmsapi05 'cat /var/log/supervisor/services.wms.error.log*'\" | grep '$1'"
}
grep_wmsapi() {
  ssh-add
  $(grep_wmsapi02 "$1")
  $(grep_wmsapi03 "$1")
  $(grep_wmsapi05 "$1")
}
grep_wmsapi_short() {
  ttab  -t "WMSAPI02" "ssh -t -A craigferguson@jump-box.takealot.com \"ssh wmsapi02 'cat /var/log/supervisor/services.wms.error.log'\" | grep '$1'"
  ttab  -t "WMSAPI03" "ssh -t -A craigferguson@jump-box.takealot.com \"ssh wmsapi03 'cat /var/log/supervisor/services.wms.error.log'\" | grep '$1'"
  ttab  -t "WMSAPI05" "ssh -t -A craigferguson@jump-box.takealot.com \"ssh wmsapi05 'cat /var/log/supervisor/services.wms.error.log'\" | grep '$1'"
}
tail_mrd() {
  ssh-add
  ttab  -t "MRD" "ssh -t -A craigferguson@jump-box.takealot.com \"ssh mrd01 'tail -n 1000 /var/log/supervisor/mrd.log'\" | grep '$1';ssh -t -A craigferguson@jump-box.takealot.com \"ssh mrd02 'tail -n 1000 /var/log/supervisor/mrd.log'\" | grep '$1'"
}
grep_mrd() {
  ssh-add
  ttab  -t "MRD" "ssh -t -A craigferguson@jump-box.takealot.com \"ssh mrd01 'cat /var/log/supervisor/mrd.log*'\" | grep '$1';ssh -t -A craigferguson@jump-box.takealot.com \"ssh mrd02 'cat /var/log/supervisor/mrd.log*'\" | grep '$1'"
}
grep_cpt_sick_logs() {
  ssh-add
  ttab -t "SICK cpt inline 1" -w "ssh -t -A craigferguson@jump-box.takealot.com \"ssh s4f-services01 'cat /var/log/supervisor/tcp_socket_client_cpt_inline_01.0.log | grep $1'\" | grep '$1' ;"
  ttab -t "SICK cpt static 1" -w "ssh -t -A craigferguson@jump-box.takealot.com \"ssh s4f-services01 'cat /var/log/supervisor/tcp_socket_client_cpt_static_01.0.log | grep $1'\" | grep '$1' ;"
  ttab -t "SICK cpt static 2" -w "ssh -t -A craigferguson@jump-box.takealot.com \"ssh s4f-services01 'cat /var/log/supervisor/tcp_socket_client_cpt_static_02.0.log | grep $1'\" | grep '$1' ;"
}
grep_jhb_sick_logs() {
  ssh-add
  ttab -t "SICK jhb inline 1" -w "ssh -t -A craigferguson@jump-box.takealot.com \"ssh s4f-services01 'cat /var/log/supervisor/tcp_socket_client_jhb_inline_01.0.log | grep $1'\" | grep '$1' ;"
  ttab -t "SICK jhb inline 2" -w "ssh -t -A craigferguson@jump-box.takealot.com \"ssh s4f-services01 'cat /var/log/supervisor/tcp_socket_client_jhb_inline_02.0.log | grep $1'\" | grep '$1' ;"
  ttab -t "SICK jhb static 1" -w "ssh -t -A craigferguson@jump-box.takealot.com \"ssh s4f-services01 'cat /var/log/supervisor/tcp_socket_client_jhb_static_01.0.log | grep $1'\" | grep '$1' ;"
  ttab -t "SICK jhb static 2" -w "ssh -t -A craigferguson@jump-box.takealot.com \"ssh s4f-services01 'cat /var/log/supervisor/tcp_socket_client_jhb_static_02.0.log | grep $1'\" | grep '$1' ;"
  }
  showcode() {
    ssh-add
    local temppath="/usr/local/tal/tal/$2"
    ssh -A craigferguson@jump-box.takealot.com ssh $1 cat $temppath
  }
  watch_sickmachine() {
    ssh-add
    ssh -t -A craigferguson@jump-box.takealot.com ./helpers/sickwatch.sh
  }
  restartCPTSICKInline() {
    ssh-add
    ssh -A craigferguson@jump-box.takealot.com ssh s4f-services01 supervisorctl restart tcp_socket_client_cpt_inline_01
  }
  restartCPTSICKStatic01() {
    ssh-add
    ssh -A craigferguson@jump-box.takealot.com ssh s4f-services01 supervisorctl restart tcp_socket_client_cpt_static_01
  }
  restartCPTSICKStatic02() {
    ssh-add
    ssh -A craigferguson@jump-box.takealot.com ssh s4f-services01 supervisorctl restart tcp_socket_client_cpt_static_02
  }
  restartJHBSICKInline01() {
    ssh-add
    ssh -A craigferguson@jump-box.takealot.com ssh s4f-services01 supervisorctl restart tcp_socket_client_jhb_inline_01
  }
  restartJHBSICKStatic01() {
    ssh-add
    ssh -A craigferguson@jump-box.takealot.com ssh s4f-services01 supervisorctl restart tcp_socket_client_jhb_static_01
  }
  restartJHBSICKStatic02() {
    ssh-add
    ssh -A craigferguson@jump-box.takealot.com ssh s4f-services01 supervisorctl restart tcp_socket_client_jhb_static_02
  }

  stop_retry_failed_order_injections() {
    #ssh -t -A craigferguson@jump-box.takealot.com "ssh toor@wmsapi02 ps aux | grep retry | awk '{print \$2}' | head -1 | xargs kill"
    ssh -t -A craigferguson@jump-box.takealot.com "ssh toor@wmsapi02 pkill -KILL -f retry_failed"
    #
    #ssh -t -A craigferguson@jump-box.takealot.com "kill \$(ps -ef | grep retry | awk '{ print \$2}' | head -1)"
  }
show_activate() {
  echo 'export ROLE=DC;source /usr/local/tal/tal/venv/bin/activate; export PYTHONPATH=/usr/local/tal/tal;'
}
run_on_wmsapi02() {
    ttab  -t "retry oi" "ssh -t -A craigferguson@jump-box.takealot.com \"ssh toor@wmsapi02 'export ROLE=DC;source /usr/local/tal/tal/venv/bin/activate; export PYTHONPATH=/usr/local/tal/tal; cd /usr/local/tal/tal/tal/services/wms/bin'\" "
}
retry_failed_order_injections() {
    ttab  -t "retry oi" "ssh -t -A craigferguson@jump-box.takealot.com \"ssh toor@wmsapi02 'export ROLE=DC;source /usr/local/tal/tal/venv/bin/activate; export PYTHONPATH=/usr/local/tal/tal; python /usr/local/tal/tal/tal/services/outbound_orders/bin/retry_failed_order_injections.py'\" "
}
POtimeout_wmsapi02() {
    ttab  -t "po timeout oi" "ssh -t -A craigferguson@jump-box.takealot.com \"ssh toor@wmsapi02 'export ROLE=DC;source /usr/local/tal/tal/venv/bin/activate; export PYTHONPATH=/usr/local/tal/tal; python /usr/local/tal/tal/tal/services/adaptris/bin/manually_approve_and_submit_po.py -i $1'\" "
}
POtimeout_E_wmsapi02() {
    ttab  -t "po timeout oi" "ssh -t -A craigferguson@jump-box.takealot.com \"ssh toor@wmsapi02 'export ROLE=DC;source /usr/local/tal/tal/venv/bin/activate; export PYTHONPATH=/usr/local/tal/tal; python /usr/local/tal/tal/tal/services/adaptris/bin/manually_approve_and_submit_po.py -i $1 -e'\" "
}
run_on_wms() {
    ssh-add
    ssh -tt -A craigferguson@jump-box.takealot.com "ssh -t wmsapi02 bash -l "
}

gpush() {
  local branch=`git rev-parse --abbrev-ref HEAD`
  [[ "$branch" == "master" ]] && echo "should be on feature branch" && return 1
  git push origin HEAD:$branch $@
}
gpr() {
  local branch=`git rev-parse --abbrev-ref HEAD`
#check tracking master
  #set following master
  [[ "$branch" == "master" ]] && echo "should be on feature branch" && return 1
git branch --set-upstream-to=origin/master branch
  git push origin HEAD:$branch || return 1
  hub pull-request -h $branch
}
grelease() {
  local branch=`git rev-parse --abbrev-ref HEAD`
  [[ "$branch" == "master" ]] && echo "should be on feature branch" && return 1
  git pull --rebase || return 1
# squash your commits into sensible chunks
  git rebase -i
  git push origin HEAD:$branch -f || return 1
  git push origin HEAD:master || return 1
  git checkout master || return 1
  git push origin :$branch || return 1
  git branch -d $branch || return 1
}

# function that will compose two other commands
#kafka commands
KRun() {
  docker run --rm -it --net=host landoop/fast-data-dev bash -c -
}
KCreate() {
  cat "kafka-topics --zookeeper 127.0.0.1:2181 --create --topic $1 --partitions 3 --replication-factor 1" | sed 's_$1_'$1'_' | KRun -
}
catdifffile() {
  cat diffs| awk '{print $14}' | awk '{print "("$1 " AND ERROR)"}'
}

# Auto convert .... to ../..
# zstyle ':prezto:module:editor' dot-expansion 'yes'

# Allow the zsh prompt context to be shown.
#zstyle ':prezto:module:editor' ps-context 'yes'

#
# Git
#

# Ignore submodules when they are 'dirty', 'untracked', 'all', or 'none'.
# zstyle ':prezto:module:git:status:ignore' submodules 'all'

#
# GNU Utility
#

# Set the command prefix on non-GNU systems.
# zstyle ':prezto:module:gnu-utility' prefix 'g'

#
# History Substring Search
#

# Set the query found color.
# zstyle ':prezto:module:history-substring-search:color' found ''

# Set the query not found color.
# zstyle ':prezto:module:history-substring-search:color' not-found ''

# Set the search globbing flags.
# zstyle ':prezto:module:history-substring-search' globbing-flags ''

#
# Pacman
#

# Set the Pacman frontend.
# zstyle ':prezto:module:pacman' frontend 'yaourt'

#
# Prompt
#

# Set the prompt theme to load.
# Setting it to 'random' loads a random theme.
# Auto set to 'off' on dumb terminals.

# Set how themes that use promptpwd function display the pwd, can be 'short', 'long', or 'full'
# zstyle ':prezto:module:prompt' pwd-length 'short'

#
# Ruby
#

# Auto switch the Ruby version on directory change.
# zstyle ':prezto:module:ruby:chruby' auto-switch 'yes'

#
# Screen
#

# Auto start a session when Zsh is launched in a local terminal.
# zstyle ':prezto:module:screen:auto-start' local 'yes'

# Auto start a session when Zsh is launched in a SSH connection.
# zstyle ':prezto:module:screen:auto-start' remote 'yes'

#
# SSH
#

# Set the SSH identities to load into the agent.
# zstyle ':prezto:module:ssh:load' identities 'id_rsa' 'id_rsa2' 'id_github'

#
# Syntax Highlighting
#

# Set syntax highlighters.
# By default, only the main highlighter is enabled.
# zstyle ':prezto:module:syntax-highlighting' highlighters \
#   'main' \
#   'brackets' \
#   'pattern' \
#   'line' \
#   'cursor' \
#   'root'
#
# Set syntax highlighting styles.
# zstyle ':prezto:module:syntax-highlighting' styles \
#   'builtin' 'bg=blue' \
#   'command' 'bg=blue' \
#   'function' 'bg=blue'
#
# Set syntax pattern styles.
# zstyle ':prezto:module:syntax-highlighting' pattern \
#   'rm*-rf*' 'fg=white,bold,bg=red'

#
# Terminal
#

# Auto set the tab and window titles.
# zstyle ':prezto:module:terminal' auto-title 'yes'

# Set the window title format.
# zstyle ':prezto:module:terminal:window-title' format '%n@%m: %s'

# Set the tab title format.
# zstyle ':prezto:module:terminal:tab-title' format '%m: %s'

# Set the terminal multiplexer title format.
# zstyle ':prezto:module:terminal:multiplexer-title' format '%s'

#
# Tmux
#

# Auto start a session when Zsh is launched in a local terminal.
 #zstyle ':prezto:module:tmux:auto-start' local 'yes'

# Auto start a session when Zsh is launched in a SSH connection.
# zstyle ':prezto:module:tmux:auto-start' remote 'yes'

# Integrate with iTerm2.
# zstyle ':prezto:module:tmux:iterm' integrate 'yes'

# Set the default session name:
 zstyle ':prezto:module:tmux:session' name 'CraigSession'

#__________NETWORKS_________________
source $HOME/git_repos/craig_help/wiki_terminal/networkrc
source $HOME/git_repos/craig_help/wiki_terminal/https
source $HOME/git_repos/craig_help/wiki_terminal/processes_and_jobs
source $HOME/git_repos/craig_help/wiki_terminal/files_permissions
source $HOME/git_repos/craig_help/wiki_terminal/linux_environment_etc
alias ewiki_networks='vim $HOME/git_repos/craig_help/wiki_terminal/networkrc'
alias ewiki_https='vim $HOME/git_repos/craig_help/wiki_terminal/https'
alias ewiki_processes_jobs='vim $HOME/git_repos/craig_help/wiki_terminal/processes_and_jobs'
alias ewiki_file_permissions='vim $HOME/git_repos/craig_help/wiki_terminal/files_permissions'
alias ewiki_file_permissions='vim $HOME/git_repos/craig_help/wiki_terminal/linux_environment_etc'

#_________RECENT___________________
# add the last command to a function wip
add_function() {
  func=$(tail -n 2 $HOME/.zhistory)
  read -r NAME <<< "$func"
  echo $read | xargs -n1 echo
}
routine() {
read -d '' help <<- EOF
ComSci:
Reading 3 hours / week
Prac HackerRank 3 hrs / week
Self Projects 5 hours / week
course 5 hours / week

Meditation:
3 hours / week
gardening 4 hours / week
reading other as many

Music:
3 hrs / week

Gym: 5 hours / week

total work time weekdays:
6-3 work (can squeeze in 3 hours of reading during lunch/morning)
3:30-4:30 gym
5-5:30 shower
6:30 - 9:00 progress
9:00 - 10:00 relax
excludes WED:
food prep 6:30-9:00 for Wed, Thurs, Fri

weekends:
meditation, garden, music
food prep on Sun for Sun, Mon, Tues
reading other

sum:
4*2.5 for progress = 10 hours a week ( need 16 )
EOF
echo "$help"
}
